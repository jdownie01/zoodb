TODO
	
	
Perf:
LongMap: Use internally bucket-arrays?!?!
         transfer is very expensive (15%of total time, 25% of makePersistentTime()!) 
                    Test after removing GENERIC stuf???
Replace ArrayLists with BucketArrayLists?
PageAccessFile_BB::isWriting : FIX remove _pageHasChanged (also in PagedObjectWriter and in Mocks!)
TODO test Iterator performance with changing frequents updates to currentPos to using a local
        variable and possibly return-values?
TODO Iterators: Shouldn't it be enough if we only clone page if it actually changed?
     So, only clone modified pages,not all of it's parents, unless we add or remove pages!!!!
	
Major short term goals:
- optimize PageAccessFile_BB.writeData() -> isWriting?!?! + remove pageHasChanged
- non-unique indices ( & bit-map index???) 
- indices in queries
- Use schema in serialized objects
- Schema evolution
- double flush() and true COW database

- Remove Versant, VException, TransSession, FundSession, Handle, COD, LOID(!) ...
	Jobs, FCO, SCO, repl, prop, ... 
	HCSS, Herschel, ESA, ....TM,DF
	
	
	
- fix query speed !!!!!!!!!!!
- Use LongMap in ClientSessionCache. AddMap<Object, CachedObject> -> see FindCO(PC)? 
  Or rather a statemanager instance per PC?
- do not load all objects! Activation depth infinity

- in rollback(): Use hollow objects instead of refreshing everything!

- Iterators (e.g. in indices): use pattern from QueryIterator: move to nextElement in findNext(),
  hasNext() returns (next!=null);

- In SerializerTools, use specialized or IdentityMap
  CHanging from HashMap/Map to IdentityMaps already increased Testharnesses from 29sec to 21 secs!!!
- (De-)Serializer: Fix loading of Keys in Sets and Maps (See TODOs).
- Store OID of schema instead of class names in DataSerializer -> REF_PERS_ID 

- preemptive commit()? -> Store objects asynchronously (no flush) when they get makeDirty()???
  -> track application: how likely is a rollback()? how often are objects changed after first change?

- Make completely copy on write
- Do not store schema (or JDO fields) in object pages

- rename nEntries to nKeys
- deRegister/invalidate iterators on commit/rollback()
- deregister iterator when hasNext()==false

- indices in queries
- clean up index implementation
- unique index: fill up pages! -> use (maxValue-minValue)=range to reduce empty space on pages.

- JDO 3.0 (&2.0?) does not require byte code enhancement!

- Optimize Page size (16KB? 4KB?)

- Freespace manager: see below
- Large Objects / free-space manager: Create non-unique OID index, contains one entry per oid-page 
  pair. Allows for non-consecutive writes, e.g. when re-using freed up pages, also avoid the POS 
  entry at the end of each page. -> This could lead to other optimisations in PageAccessFile(?).
  The POS index contains all pages. -> effectively, we have now a free-space manager. If the POS
  manager has no other objects on that page, then the page is free. 

- TODO PagedObjectAccess tries to group object into pages, while the underlying PageAccessFile just
  writes a continuous stream of objects. Fix this! -> Probably just fix the PagedObjectAccess.
  -> Result: All objects, regardless of size are just written one after the other in a continuous
    stream. A new stream is only started for a new class (rationale???? Why not simply a continuous
    stream for all objects? -> grouping is good for queries and schema evolution. But would it be
    harmfull if objects of different class would be on a page as long as they are generally sorted 
    by class? The benefit would be that a) a transaction may just write a single data page, if 
    multiple small objects of different classes are involved. b) it makes future implementation
    of clustering simpler.).
    On the other hand, if we would dedicate pages to a specific class, we could start filling
    up half-full pages of smaller object over multiple transactions. That slows down writing, 
    because we may have to read the old page first, and not all objects may fit on the new page.
    But subsequent reading (e.g. for queries) may be faster, because the objects are spread over
    fewer pages. We then should also distinguish small and large objects, the latter ones would
    otherwise risk to have their tail moved to a different area on the disk.


READ Java news #15 / #98  -> Don't use weak refs in Cache!



Commit optimization
-------------------
Use separate thread for 'optimistic' serialization, hoping that objects do not change again.
-> Measure times serialization<->index_update<->write+flush()
-> patenable?????

Asynchronous flush().
-> Measure whether flush() really blocks.
If it does, perform it asynchronously in a separate thread. However subsequent read/write-ops 
should block until flush() is finished.

