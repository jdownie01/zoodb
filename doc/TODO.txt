TODO
	
Major short term goals:
- non-unique indices ( & bit-map index???) 
- indices in queries
- Use schema in serialized objects
- Schema evolution
- double flush() and true COW database

	
- fix query speed !!!!!!!!!!!
- Use LongMap in ClientSessionCache. AddMap<Object, CachedObject> -> see FindCO(PC)? 
  Or rather a statemanager instance per PC?
- do not load all objects! Activation depth infinity

- in rollback(): Use hollow objects instead of refreshing everything!

- Iterators (e.g. in indices): use pattern from QueryIterator: move to nextElement in findNext(),
  hasNext() returns (next!=null);

- In SerializerTools, use specialized or IdentityMap
  CHanging from HashMap/Map to IdentityMaps already increased Testharnesses from 29sec to 21 secs!!!
- (De-)Serializer: Fix loading of Keys in Sets and Maps (See TODOs).
- Store OID of schema instead of class names in DataSerializer -> REF_PERS_ID 

- preemptive commit()? -> Store objects asynchronously (no flush) when they get makeDirty()???
  -> track application: how likely is a rollback()? how often are objects changed after first change?

- Make completely copy on write
- Do not store schema (or JDO fields) in object pages

- rename nEntries to nKeys
- deRegister/invalidate iterators on commit/rollback()
- deregister iterator when hasNext()==false

- indices in queries
- clean up index implementation
- unique index: fill up pages! -> use (maxValue-minValue)=range to reduce empty space on pages.

- JDO 3.0 (&2.0?) does not require byte code enhancement!

- Freespace manager
- Optimize Page size (16KB? 4KB?)


- TODO PagedObjectAccess tries to group object into pages, while the underlying PageAccessFile just
  writes a continuous stream of objects. Fix this! -> Probably just fix the PagedObjectAccess.
  -> Result: All objects, regardless of size are just written one after the other in a continuous
    stream. A new stream is only started for a new class (rationale???? Why not simply a continuous
    stream for all objects? -> grouping is good for queries and schema evolution. But would it be
    harmfull if objects of different class would be on a page as long as they are generally sorted 
    by class? The benefit would be that a) a transaction may just write a single data page, if 
    multiple small objects of different classes are involved. b) it makes future implementation
    of clustering simpler.).
    On the other hand, if we would dedicate pages to a specific class, we could start filling
    up half-full pages of smaller object over multiple transactions. That slows down writing, 
    because we may have to read the old page first, and not all objects may fit on the new page.
    But subsequent reading (e.g. for queries) may be faster, because the objects are spread over
    fewer pages. We then should also distinguish small and large objects, the latter ones would
    otherwise risk to have their tail moved to a different area on the disk.


READ Java news #15 / #98  -> Don't use weak refs in Cache!



Commit optimization
-------------------
Use separate thread for 'optimistic' serialization, hoping that objects do not change again.
-> Measure times serialization<->index_update<->write+flush()

Asynchronous flush().
-> Measure whether flush() really blocks.
If it does, perform it asynchronously in a separate thread. However subsequent read/write-ops 
should block until flush() is finished.

