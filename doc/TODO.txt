TODO
	
- PolePos: Should (e.g. Sepang) be changed to use larger activation depth? I.e. load all Trees at
  once using a query on the class?
- Check why Zoo is slow in melbourne courses!!!
- BucketArrayList in OGT? Test e.g. with melbourne!
- implement DBList and DBMap to avoid set/map stuff in DataDeserializer
- Remove StateManagerImpl
	
Perf:
- check why call to writeXYZ in PegaedObjectAccess are so expensive (Serializer.testLargeObjects()
- FSM: do not store flag?!?!
- Statemanager: store oid locally and return it (avoid cast/call in getObjectId())? Avoid boxing?
- Avoid autoboxing in calls to PCI.getObjectId()
- look again at using MemoryMappedFile (possibly many of them, each 16 pages???). Would avoid
  a certain amount of copying. 
	
Index:	
- improve overflow in addSubPage
- Turn Schemata into objects using PagedObjectAccess -> allows proper use of FSM ->
  check in PagedObjectAccess for POA-callback==null not required.
		
- Test harness for index creation and updates (i.e. object changes value)
- Implement InMemoryDB in Avon
- Test & implement: Queries should consider cached (and possibly modified) objects
	
FIX:
- In PagedIndex: check that key in parent is updated if keys[0] is set to a lower value (or
  to a higher, but that is less critical).
	
- Check counted B-Tree:
http://www.chiark.greenend.org.uk/~sgtatham/algorithms/cbtree.html

- Decide on concurrency pattern for BucketArrayList iterator (see javadoc of iterator).


Perf:
Consider ConcurrentSkipLists, e.g. for cache/OGT. Needs confirmation, but probably does not use an 
	array and is therefore better for adding objects (no array resizing). 
LongMap: Use internally bucket-arrays?!?!
         transfer is very expensive (15%of total time, 25% of makePersistentTime()!) 
                    Test after removing GENERIC stuff???

	
Major short term goals:
- indices in queries
- use smaller index entries for types shorter than 'long'?
- Schema evolution

- improve index page usage:
  a) When splitting, first attempt to distribute over subsequent and previous page. This should 
     satisfy evenly distributed insertions, even with b) in place.
  b) If a) fails, create new page that contains 25%(33%?) of the entries. This should satisfy
     increasing numbers. For decreasing numbers, this should also work, because an overflowing
     page first distribute to neighbouring pages. Question: do we need b) at all? Probably not! 
     At least not, if previous and following pages are always (both?) filled. 	
  -> Fix MAX_DEPTH constants in Index tests!
	
	
	
- Make MergingIterator multi-threaded (see TODO in class)
- Use LongMap in ClientSessionCache. AddMap<Object, CachedObject> -> see FindCO(PC)? 
  Or rather a statemanager instance per PC?
- do not load all objects! Activation depth infinity

- in rollback(): Use hollow objects instead of refreshing everything!

- Iterators (e.g. in indices): use pattern from QueryIterator: move to nextElement in findNext(),
  hasNext() returns (next!=null);

- In SerializerTools, use specialized or IdentityMap
  CHanging from HashMap/Map to IdentityMaps already increased Testharnesses from 29sec to 21 secs!!!
- (De-)Serializer: Fix loading of Keys in Sets and Maps (See TODOs).

- preemptive commit()? -> Store objects asynchronously (no flush) when they get makeDirty()???
  -> track application: how likely is a rollback()? how often are objects changed after first change?
  To handle preemptive commit, reset the pageCount if the writer to the count as it was before the
  preemptive commit was initiated. 

- rename nEntries to nKeys
- deRegister/invalidate iterators on commit/rollback()
- deregister iterator when hasNext()==false

- indices in queries
- clean up index implementation

- JDO 3.0 (&2.0?) does not require byte code enhancement!

- Optimize Page size (16KB? 4KB?)

- Pos/schema index. should we remove this? If it is only used to speed up queries that have other-
  wise no index, then it may be better to scrap it.... (?). 

- Freespace manager 2.0:
  Use separate index for free pages. Do not use a BitMap, that would only pay out if more than 1/32
  of all pages would be free.
  The manager should only return pages that were freed up during previous transactions, but not
  in the current one. To do so, in the freespace manager, create a new iterator(MIN_INT/MAX_INT) for
  every new transaction. The iterator will return only free pages from previous transactions.
  If (iter.hasNext() == false), use atomic page counter to allocate additional pages.
  
- Freespace manager: see below
- Large Objects / free-space manager: Create non-unique OID index, contains one entry per oid-page 
  pair. Allows for non-consecutive writes, e.g. when re-using freed up pages, also avoid the POS 
  entry at the end of each page. -> This could lead to other optimisations in PageAccessFile(?).
  The POS index contains all pages. -> effectively, we have now a free-space manager. If the POS
  manager has no other objects on that page, then the page is free. 

- TODO PagedObjectAccess tries to group object into pages, while the underlying PageAccessFile just
  writes a continuous stream of objects. Fix this! -> Probably just fix the PagedObjectAccess.
  -> Result: All objects, regardless of size are just written one after the other in a continuous
    stream. A new stream is only started for a new class (rationale???? Why not simply a continuous
    stream for all objects? -> grouping is good for queries and schema evolution. But would it be
    harmfull if objects of different class would be on a page as long as they are generally sorted 
    by class? The benefit would be that a) a transaction may just write a single data page, if 
    multiple small objects of different classes are involved. b) it makes future implementation
    of clustering simpler.).
    On the other hand, if we would dedicate pages to a specific class, we could start filling
    up half-full pages of smaller object over multiple transactions. That slows down writing, 
    because we may have to read the old page first, and not all objects may fit on the new page.
    But subsequent reading (e.g. for queries) may be faster, because the objects are spread over
    fewer pages. We then should also distinguish small and large objects, the latter ones would
    otherwise risk to have their tail moved to a different area on the disk.


READ Java news #15 / #98  -> Don't use weak refs in Cache!



Commit optimization
-------------------
Use separate thread for 'optimistic' serialization, hoping that objects do not change again.
-> Measure times serialization<->index_update<->write+flush()
-> patentable?????

Asynchronous flush().
-> Measure whether flush() really blocks.
If it does, perform it asynchronously in a separate thread. However subsequent read/write-ops 
should block until flush() is finished.



publishable?
============
-> improved B_Tree filling? (unique, merge with prev and subsequent)
-> FSM solution to page allocation problem? 